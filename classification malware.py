import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import numpy as np
from sklearn.metrics import accuracy_score

# load data
dataset = pd.read_csv('Output_clean_CSV/PE++++.csv')
dataset = dataset.dropna()
# print('nilai duplikat', dataset.duplicated().value_counts())
maldata = dataset.drop(['Name','Md5'], axis=1)
print("===========================================================================================")
print("*The Dataset*")
print("Shape of Dataset Malware and Goodware:",maldata.shape)

df = maldata
X  = df.iloc[:, 0:88].values
y  = df.iloc[:, 88].values

# Random Forest importance
clf = RandomForestClassifier(random_state=0)
model = clf.fit(X, y)
select = SelectFromModel(model,prefit=True)
X_new = select.transform(X)
print("===========================================================================================")
print("*Feature Selection*")
print("Shape before using feature selection:",X.shape)
print("Shape after feature selection:",X_new.shape)

importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

# List of Feature
print("Feature ranking List:")
for f in range(X_new.shape[1]):
    print("%d. %s (%f)" % (f + 1, df.columns[indices[f]], importances[indices[f]]))
print("===========================================================================================")
print("*PCA and Naive Bayes*")
# Looping to get the maximum accuracy
for i in range(X_new.shape[1]):
    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.2, random_state = 42)
    sc = StandardScaler()
    X_train_scaled = sc.fit_transform(X_train)
    X_test_scaled = sc.transform(X_test)

    pca = PCA(n_components = i+1)
    X_train = pca.fit_transform(X_train_scaled)
    X_test = pca.transform(X_test_scaled)
    print('Variance sum ke ', i+1, ' :', pca.explained_variance_ratio_.cumsum()[-1])

    # Get Eigen Value
    # np.set_printoptions(suppress=True)
    # cov = np.cov(X_train_scaled.T)
    # eig_val, eig_vec = np.linalg.eig(cov)
    # print('Eigenvalues = ', eig_val)


    # Mengaktifkan/memanggil/membuat fungsi klasifikasi Naive bayes
    modelnb = GaussianNB()
    # Memasukkan data training pada fungsi klasifikasi naive bayes
    nbtrain = modelnb.fit(X_train, y_train)
    nbtrain.class_count_

    # Menentukan hasil prediksi dari x_test
    y_pred = nbtrain.predict(X_test)
    # print(y_pred)

    # Menentukan probabilitas hasil prediksi
    nbtrain.predict_proba(X_test)

    # import confusion_matrix model
    print(confusion_matrix(y_test, y_pred))

    # Menghitung nilai akurasi dari klasifikasi naive bayes
    print(classification_report(y_test, y_pred))
    print(accuracy_score(y_test, y_pred))
print("===========================================================================================")
