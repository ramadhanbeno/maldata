import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
import time

start_time = time.time()
# load data
dataset = pd.read_csv('Output_clean_CSV/dynamic.csv')
dataset = dataset.dropna()
# print('nilai duplikat', dataset.duplicated().value_counts())
maldata = dataset.drop(['Name'], axis=1)
print("===========================================================================================")
print("Shape of dataset:",maldata.shape)
print("===========================================================================================")
df = maldata
X  = df.iloc[:, 0:100].values
y  = df.iloc[:, 100].values

# Random Forest importance
clf = RandomForestClassifier(random_state=0)
model = clf.fit(X, y)
select = SelectFromModel(model,prefit=True)
X_new = select.transform(X)
print("*Feature Selection*")
print("Shape before using feature selection:",X.shape)
print("Shape after feature selection:",X_new.shape)
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
# print(importances)
# List of Feature
print("Feature ranking:")
for f in range(X_new.shape[1]):
    print("%d. %s (%f)" % (f + 1, df.columns[indices[f]], importances[indices[f]]))
print("===========================================================================================")
# Visualization feature
names = [df.columns[i] for i in indices]
plt.figure(figsize=(60, 30))
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[indices])
plt.xticks(range(X.shape[1]), names, rotation=90, fontsize=8)
plt.show()

# Split data train dan test
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.2, random_state = 0)
# Standarisasi xtrain dan xtest
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# hasil standarisasi xtrain dan xtest
importances_cols = [df.columns[indices[i]] for i in range(X_new.shape[1])]
sd_xtrain = pd.DataFrame(X_train,columns=importances_cols)
sd_xtest = pd.DataFrame(X_test,columns=importances_cols)
print("###DATA STANDARIZATION X TRAIN###")
print(sd_xtrain)
print("###DATA STANDARIZATION X TEST###")
print(sd_xtest)

# Get Eigen Value
np.set_printoptions(suppress=True)
cov = np.cov(X_train.T)
eig_val, eig_vec = np.linalg.eig(cov)
print("===========================================================================================")
print('Eigenvalues = ', eig_val)
print("===========================================================================================")
# Reduksi Fitur menggunakan PCA
pca_comp = 43
pca = PCA(n_components = pca_comp)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
print("PCA with ",pca_comp," PCA Component")
print('Variance :', pca.explained_variance_ratio_.cumsum()[-1])
# Hasil dari proses PCA
pc_columns = ["PC"+str(i+1) for i in range(pca_comp)]
pca_mal_train = pd.DataFrame(data = X_train, columns = pc_columns)
pca_mal_test = pd.DataFrame(data = X_test, columns = pc_columns)
print("###DATA PCA X_TRAIN###")
pca_mal_train['label']=y_train
print(pca_mal_train)
# pca_mal_train.to_csv('Output_clean_CSV/Dynamic_data_PCA_train.csv', index=False)
print("###DATA PCA X_TEST###")
print(pca_mal_test)
# pca_mal_test.to_csv('Output_clean_CSV/Dynamic_data_PCA_test.csv', index=False)
print("===========================================================================================")
print("The amount of data testing",len(y_test))
print("Label for testing data:",y_test)

# Klasifikasi menggunakan Naive Bayes
# Mengaktifkan/memanggil/membuat fungsi klasifikasi Naive bayes
modelnb = GaussianNB()
# Memasukkan data training pada fungsi klasifikasi naive bayes
nbtrain = modelnb.fit(X_train, y_train)
nbtrain.class_count_

# Menentukan hasil prediksi dari x_test
y_pred = nbtrain.predict(X_test)
print("Test == Predict")
print(y_pred==y_test)

# Menentukan probabilitas hasil prediksi
nbtrain.predict_proba(X_test)

# import confusion_matrix model
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

# Menghitung nilai akurasi dari klasifikasi naive bayes
print(classification_report(y_test, y_pred))
print("Accuracy Score:",accuracy_score(y_test, y_pred))
print("--- %s seconds ---" % (time.time() - start_time))

